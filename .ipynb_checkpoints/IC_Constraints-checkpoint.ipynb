{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrity constraints with Python and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we convert our files into sqlite tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "con = sqlite3.connect(\"salary_responses.db\", timeout = 10)\n",
    "df = pd.read_csv('Data/salary_responses.csv')\n",
    "df_clean = pd.read_csv('Data/data_full.csv')\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns = df.columns.str.strip()\n",
    "df_clean.columns = df_clean.columns.str.strip()\n",
    "\n",
    "# Creating tables\n",
    "df.to_sql(\"SalaryResponsesDirty\", con)\n",
    "df_clean.to_sql(\"SalaryResponsesClean\", con)\n",
    "con.cursor().close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function to get the column names for our original \"dirty\" file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_names(table):\n",
    "    con = sqlite3.connect(\"salary_responses.db\")\n",
    "    cur = con.cursor()\n",
    "    query = 'SELECT * FROM {}'.format(table)\n",
    "    cur.execute(query)\n",
    "    cur.close()\n",
    "    return [member[0] for member in cur.description]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_names = get_col_names('SalaryResponsesDirty')\n",
    "clean_names = get_col_names('SalaryResponsesClean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the column names for the original date are extremely long and contain special characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirty File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "Timestamp\n",
      "How_old_are_you?\n",
      "What_industry_do_you_work_in?\n",
      "Job_title\n",
      "If_your_job_title_needs_additional_context,_please_clarify_here:\n",
      "What_is_your_annual_salary?_(You'll_indicate_the_currency_in_a_later_question._If_you_are_part-time_or_hourly,_please_enter_an_annualized_equivalent_--_what_you_would_earn_if_you_worked_the_job_40_hours_a_week,_52_weeks_a_year.)\n",
      "How_much_additional_monetary_compensation_do_you_get,_if_any_(for_example,_bonuses_or_overtime_in_an_average_year)?_Please_only_include_monetary_compensation_here,_not_the_value_of_benefits.\n",
      "Please_indicate_the_currency\n",
      "If_\"Other,\"_please_indicate_the_currency_here:_\n",
      "If_your_income_needs_additional_context,_please_provide_it_here:\n",
      "What_country_do_you_work_in?\n",
      "If_you're_in_the_U.S.,_what_state_do_you_work_in?\n",
      "What_city_do_you_work_in?\n",
      "How_many_years_of_professional_work_experience_do_you_have_overall?\n",
      "How_many_years_of_professional_work_experience_do_you_have_in_your_field?\n",
      "What_is_your_highest_level_of_education_completed?\n",
      "What_is_your_gender?\n",
      "What_is_your_race?_(Choose_all_that_apply.)\n"
     ]
    }
   ],
   "source": [
    "print(*dirty_names, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level_0\n",
      "timestamp\n",
      "age\n",
      "industry\n",
      "job_title\n",
      "annual_salary\n",
      "additional_salary\n",
      "currency\n",
      "country\n",
      "state\n",
      "city\n",
      "total_experience\n",
      "current_experience\n",
      "education\n",
      "gender\n",
      "race\n",
      "age_min\n",
      "age_max\n",
      "total_experience_min\n",
      "total_experience_max\n",
      "current_experience_min\n",
      "current_experience_max\n",
      "education_lvl\n",
      "gender_idx\n",
      "continent\n",
      "lat_long\n",
      "lat\n",
      "long\n",
      "USD_rate\n",
      "annual_salary_USD\n",
      "additional_salary_USD\n",
      "total_salary_USD\n",
      "race_idx\n",
      "index\n",
      "job_title_clean\n",
      "industry_clean\n",
      "total_salary\n"
     ]
    }
   ],
   "source": [
    "print(*clean_names, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dirty file's column names are very difficult to work with, we will continue our Integrity Constraint checks with clean column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.set_axis(['index','timestamp', 'age', 'industry', 'job_title', 'job_context','annual_salary',\n",
    "                      'additional_salary', 'currency', 'currency_context', 'country',\n",
    "                      'state', 'city', 'total_experience', 'current_experience', 'education',\n",
    "                    'gender', 'race'], axis = 1, inplace=False)\n",
    "con = sqlite3.connect(\"salary_responses.db\")\n",
    "cur = con.cursor()\n",
    "new_df.to_sql(\"SalaryDirtyUpdated\", con)\n",
    "con.cursor().close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get the unique values in the Education column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values(col, table):\n",
    "    con = sqlite3.connect(\"salary_responses.db\")\n",
    "    cur = con.cursor()\n",
    "    query = 'SELECT DISTINCT {} FROM {}'.format(col, table)\n",
    "    cur.execute(query)\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    return [i[0] for i in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirty File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Master's degree\", 'College degree', 'PhD', None, 'Some college', 'High School', 'Professional degree (MD, JD, etc.)']\n"
     ]
    }
   ],
   "source": [
    "print(unique_values('education', 'SalaryDirtyUpdated'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Master's degree\", 'College degree', 'PhD', None, 'Some college', 'High School', 'Professional degree']\n"
     ]
    }
   ],
   "source": [
    "print(unique_values('education', 'SalaryResponsesClean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For race, we opted to create a boolean mask for the clean file to facilitate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirty File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White\n",
      "Hispanic, Latino, or Spanish origin, White\n",
      "Asian or Asian American, White\n",
      "Asian or Asian American\n",
      "Another option not listed here or prefer not to answer\n",
      "Hispanic, Latino, or Spanish origin\n",
      "Middle Eastern or Northern African\n",
      "Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White\n",
      "Black or African American\n",
      "Black or African American, White\n",
      "None\n",
      "Black or African American, Hispanic, Latino, or Spanish origin, White\n",
      "Native American or Alaska Native\n",
      "Native American or Alaska Native, White\n",
      "Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer\n",
      "Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White\n",
      "White, Another option not listed here or prefer not to answer\n",
      "Black or African American, Native American or Alaska Native, White\n",
      "Asian or Asian American, Another option not listed here or prefer not to answer\n",
      "Middle Eastern or Northern African, White\n",
      "Asian or Asian American, Black or African American, White\n",
      "Black or African American, Hispanic, Latino, or Spanish origin\n",
      "Asian or Asian American, Black or African American\n",
      "Asian or Asian American, Hispanic, Latino, or Spanish origin, White\n",
      "Native American or Alaska Native, White, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, Hispanic, Latino, or Spanish origin\n",
      "Asian or Asian American, Native American or Alaska Native, White\n",
      "Hispanic, Latino, or Spanish origin, Native American or Alaska Native\n",
      "Black or African American, Middle Eastern or Northern African, White\n",
      "Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White\n",
      "Black or African American, Another option not listed here or prefer not to answer\n",
      "Native American or Alaska Native, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, White, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, Middle Eastern or Northern African\n",
      "Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White\n",
      "Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African\n",
      "Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White\n",
      "Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer\n",
      "Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, Black or African American, Hispanic, Latino, or Spanish origin\n",
      "Asian or Asian American, Black or African American, Native American or Alaska Native, White\n",
      "Middle Eastern or Northern African, Native American or Alaska Native, White\n",
      "Asian or Asian American, Middle Eastern or Northern African, White\n",
      "Black or African American, Middle Eastern or Northern African\n",
      "Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, Native American or Alaska Native\n",
      "Middle Eastern or Northern African, Native American or Alaska Native\n",
      "Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer\n",
      "Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer\n"
     ]
    }
   ],
   "source": [
    "print(*unique_values('race', 'SalaryDirtyUpdated'), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "4,7\n",
      "1,7\n",
      "1\n",
      "8\n",
      "4\n",
      "5\n",
      "4,5,7\n",
      "2\n",
      "2,7\n",
      "None\n",
      "2,4,7\n",
      "6\n",
      "6,7\n",
      "4,8\n",
      "2,5,6,7\n",
      "7,8\n",
      "2,6,7\n",
      "1,8\n",
      "5,7\n",
      "1,2,7\n",
      "2,4\n",
      "1,2\n",
      "1,4,7\n",
      "6,7,8\n",
      "1,4\n",
      "1,6,7\n",
      "4,6\n",
      "2,5,7\n",
      "2,4,6,7\n",
      "2,8\n",
      "6,8\n",
      "1,7,8\n",
      "1,5\n",
      "1,4,6,7\n",
      "4,5\n",
      "4,6,7\n",
      "5,7,8\n",
      "4,7,8\n",
      "1,2,4\n",
      "1,2,6,7\n",
      "5,6,7\n",
      "1,5,7\n",
      "2,5\n",
      "4,6,8\n",
      "1,6\n",
      "5,6\n",
      "1,4,8\n",
      "1,4,7,8\n"
     ]
    }
   ],
   "source": [
    "print(*unique_values('race_idx', 'SalaryResponsesClean'), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_ic(col, table):\n",
    "    con = sqlite3.connect(\"salary_responses.db\")\n",
    "    cur = con.cursor()\n",
    "    query = \"SELECT DISTINCT {} FROM {} WHERE {} LIKE ?\".format(col, table, col)\n",
    "    cur.execute(query,('%United States%',))\n",
    "    res = cur.fetchall()\n",
    "    cur.close()\n",
    "    return [i[0] for i in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the IC for country by checking the unique values entered for the `United States` as an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dirty File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n",
      "United States \n",
      "United States of America\n",
      "United states\n",
      "United states \n",
      "united states\n",
      "United States of America \n",
      "united states of america\n",
      "The United States\n",
      "UNITED STATES\n",
      "united States\n",
      "United States of American \n",
      "United States (I work from home and my clients are all over the US/Canada/PR\n",
      "United Statesp\n",
      "UNited States\n",
      "United States of Americas\n",
      "United States of america \n",
      "united states \n",
      "United states of America \n",
      "For the United States government, but posted overseas\n",
      "United States of america\n",
      " United States\n",
      "United States Of America\n",
      "United states of America\n",
      "United STates\n",
      "United States- Puerto Rico\n",
      "United states of america\n",
      "United States is America\n",
      "United States of American\n"
     ]
    }
   ],
   "source": [
    "print(*country_ic('country', 'SalaryDirtyUpdated'), sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean File:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States\n"
     ]
    }
   ],
   "source": [
    "print(*country_ic('country', 'SalaryResponsesClean'), sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
